### normalizing flows

explicit marginal likelihood
- requires the model to be 
    - diff.able, invertable, efficient Jacobian
    - for efficient Jacob: better to be lower tri.
- couping layer
    - beta: can be not invertable
    - h typically element wise function
- flow of transformations
    - training model: max. exact llh of the dataset
- how to shuffle/split x into x_A, x_B?
    - constraint: f: R^k -> R^k
    - split into channels, downsample spacially (squeeze and split)
    - flow block: actnorm, 1*1 conv, affine coupling
        - act norm: element wise,, scale and bias trainable
        - 1*1 conv: log determinant in O(C^3)
            - W = PL(U + diag(s)), P is precomputed, L U learnable
        - conditional coupling layers
            - Jacobian still of the same formula
- styleflow
    - pretrained attribute classifier
    - CNF to model weight space of style GAN