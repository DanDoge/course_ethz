### deep generative models

unsupervised learning
- data x, without labels
- learn underlying hidden structure of data
    - e.g. clustering, feature learning, dim. reduction, density estimation
- generative modeling
    - generate new samples from the same distribution
    - learn p_model similar to p_data
        - explicitly define p_model, e.g. learn a Gaussian with mu and Cov
            - VAE, autoregressive models, Norm. flows, invertible N
        - or implicitly sample p_model
            - GAN
- latent space: find meaningful DoF with low dimentional code
    - hidden layer dim < dim(x)
    - autoencoders performs bad for out of distribution samples
    - denoise AE: randomly set parts to 0, add Gaussian noise, then force the NN to reconstruct
    - but AE's decoder cannot synthesize realistic images
        - the latent space is not well sturctured
- VAE: the embedding space follow a Gaussin distribution