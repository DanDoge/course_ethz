### deep neural networks

compositional models
- feature engineering, feature expansion, compositionality
    - DNN combine compositionality and expansiveness
- linear functions: no compositionalality
    - introduce ridge function
    - minimal ridge function: one hidden layer, a non poly activation function are universal functional approx.ors
- clasiscal MLP
    - sigmoid network: beta / (1 + exp(-theta * x))

BP
- jacobi matrix / map
    - part l / part H_k = (part H_k+1 / part H_k)^T part l / part H_k+1
    - part l / part H_k+1: (n_k+1, 1)
    - part H_k+1 / part H_k: (n_k+1, n_k)
    - eval jacobi map requires forward pass in DNN