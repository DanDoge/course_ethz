### active learning

use uncerzainty for deciding which data to collect
- recall GP: posterior variance k(x, x') and sigma_t does not depende on y_t
- query points that provides most useful information
- mutual information
    - I(X; Y) = H(X) - H(X | Y), by observing y, how much uncertainty reduced
        - H(X | Y) = E_y H(X | y)
        - I(X; Y) = I(Y; X)
        - H(X) + H(Y | X) = H(X, Y)
- find S max. information gain
    - F(S) = H(f) - H(f | y_S) = I(f ; y_S) = 1/2 log |I + sigma^-2 K_S|
        - f is jointly Gaussian, y_S = f + epsilon
    - greedy: for S_t = x_1...t, x_t = argmax F(S_t U x)
    = F(S_t U x) - F(S_t)
    = I(f ; y | y_S)
    = 1/2 log(1 + sigma^-2 simga_t^2(x))
        - for homoscedastic case, = argmax sigma_t^2(x)
        - uncertainty sampling
        - for isotrophic GP case, results in uniform sampling
    - F(S) is monotone submodular: F(A U x) - F(A) >= F(B U x) - F(B), for A in B
        - lhs = F(x | A) = H(y_x | y_A) - H(y_x | f)
            - H(f) - H(f | y_A, y_x) - H(f) + H(f | y_A)
            = H(f | y_A) - H(f | y_A, y_x)
            = I(f ; y_x | y_A)
            = I(y_x ; f | y_A)
            = H(y_x | y_A) - H(y_x | f), note that conditioned on f, y_x and y_A are independent, and thus H(y_x | f, y_A) = H(y_x | f)
        - we need H(y_x | y_A) >= H(y_x | y_B), conditioning on more information will always decrease entropy
    - greedy F(S_T) >= (1 - 1 / e) max F(S)
- active learning for classification
    - informative sampling for classification
        - x = argmax I(theta ; y_x | X, Y)
        = H(y | x, X, Y) - E_theta H(y | x, theta)
        = approx. by predictive distribution from approx. posterior - 1/m sum of H(y | x, theta_i)

bayesian optimization
- learn a model of the blackbox function
- x, learn GP(x), get lower bound(for some sigma)
    - max f >= best lower bound
    - only focuses on where upper bound(for the same sigma) is above the bset lower bound