### federated learning

learn w/o individuals sharing data
- cross-device setting
    - small amount of data per source, sources dynamically drop in and out
- cross sillo setting
    - small number of sources with heterogenous data
- federated server / individual clients / local updates
    - private data must not be exposed
    - client send: local updates, local training statistics
    - server aggregate local updates
- FedSGD
    - client choose random private data, local updates as gradients w.r.t. global model
    - server applies avg gradient update using SGD
    - guarantee of convergence, but expensive communication
- FedAvg
    - serveral SGD on clinet local model
    - server avg weights of local model
    - less communication, no guarantees of convergence
- server-side attacks
    - from client local updates and stats, expoes private data of clients
        - malicious updates of global model not allowed
    - argmin |partial L(f(x_i), y_i) - partial L(f(x), y)| + R(x)
        - R enforces realistic images, e.g. total variation
    - prob. view of gradient inversion function
        - assume client gradient g_k is corrupted of true gradient
        - argmax p(partial L(f(x), y) = g_k | x, y) * p(x)
        - prefer strong image priors
- client-side attacks
    - send malicious local updates to server
    - coordination between clients allowed
    - client fairness: variance of accuracy of global model across clients
    - server cannot distinguish heterogeneous / adversarial clients

differential privacy
- for similar dataset D, D' P(M(D) in S) < exp(eps) P(M(D') in S) + delta
- DP-SGD, clips norm of gradinets to C, add Gaussian noise

model personalization
- clients can personalize global models locally -> fairness
- personalization is local -> defence w.r.t. malicious clients