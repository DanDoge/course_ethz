### classification

ROC receiver operating clavacterstive?
- start with classifier that returns pi^hat(x) = p(y = 1 | x)
- coenvert to {0, 1} if pi^hat(x) >= theta
- for test data, get 2*2 table: true class v.s. predicted label
- sensitivity: TP / (TP + FN) 
- specificity: TN / (TN + FP)
- plot sens w.r.t. spec by tuning theta
    - for random guess: straight line
- spec can only take n values, n = # of y = 0
    - AUC = p(pi^hat_i_1 > pi^hat_i_0)
        - i_1 uniformly chosen from y = 1 and so for i_0
        - pick a random i_0, set theta = pi^hat_i_0, see how much samples with y = 1 are with larger prob

### additive models

model y = sum_p g_p(x_k) + eps, want to get estimate of y^hat = sum_p g_p^hat(x)
- fit p function for each coordinate
- for identifiability, subtract the mean
    - and then E g_i = 0
    - backfitting
        - start with mu^hat = E_n(y), g_p = 0
        - for each k in 1...p, optimise g^hat_k with target y - other functions under regularization
        - repeat until convergence
    - let x_k,i being the k-th variable in sample i
    - if x_k are dependent, the model assumption also does not work
        - the individual fit does not work, (identifiability)

```r
p = 3
n = 1000
X = matrix(rnorm(n * p), ncol = p)
g <- function(x, k) x^k

Y = g(X[, 1], 1) + g(X[, 2], 2) + g(X[, 3], 3) + rnorm(n)

muhat = mean(Y)
ghat = matrix(0, nrow=n, ncol=p)
for (k in sample(1:p, p)){ # for random order
    res = Y - muhat - apply(ghat[-k], 1, sum)
    smo = smooth.spline(X[, k], res, spar=0.8)
    yhat = predict(smo, X[, k])$y
    ghat[, k] = yhat - mean(yhat) # for identifiability

}
```