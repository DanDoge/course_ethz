### classification

QDA
- model p(y = j) = p_j, p(x | y = j) = N(mu_j, Sigma_j)
- c^hat(x) = argmax_j log(p^hat_j) - .5 * log(det Sigma^hat_j) - .5 quad term
    - quadratic deciison boundary

logistic regression: linear model for pi(x) = p(y = 1 | x)
- for binary case
- lienar model for log (pi(x) / (1 - pi(x))) = beta^T x or g(x)
    - pi(x) = 1 / (1 + exp(-beta^T x))
    - l = Prod pi(x_i)^y_i (1 - pi(x_i))^(1 - y_i)
    - nll = - sum y_i log pi(x_i)/(1 - pi(x_i)) + log(1 - pi(x_i))
    = - sum y_i beta^T x_i - log(1 + exp(beta^T x_i))
    - let z_i = beta^T x_i, for y = 0, nll = log(1 + exp(z_i))
        - note nll are to be minmized: for y = 0, beta^T x should -> -infty, pi(x) = 0
        - for y = 1, nll = -z + log(1 + exp(z)), are a flipped version of y = 0
        - in both case: convex
            - so nll for all data is also convex, but not quadratic though
- local quadratic estimation
- multiclass softmax(Beta x) = exp(beta^j^T x) / sum_j'

```r
glm(Y ~ X, family='binomial')
mult = multinom(Y ~ ., data=X)
predict(mult, newdata = X)

mult = multinom(Y ~ .^2, data=X[train]) # some quadratic logit. reg.
predict(mult, newdata = X[test])
```