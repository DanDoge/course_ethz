### cross validation

validation problem
- quantify performance on unseen data
- CV error
    - training data {(x_i, y_i)}, rnadomly partition into k equal disjoint bins
    - m^hat_T being the model on whole training data, m^hat_i fitted on data w/o bin_i
    - for each b_j, estimate error as err_j = 1/|b_j| sum_obs in bin_j (y_obs - m^hat_j(x_obs))^2
    - cv(m^hat) = avg_j err_j, but what is it estimating?
- conditional v.s. overall test error
    - fitting model m^hat on T -> m^hat_T
    - training error: 1/|T| sum (m^hat_T(x_i) - y_i)^2
    - conditional test error: 1/m sum (m^hat_T(x_i) - y_i)^2, on m sampled test data
        - conditional on training set T
        - population version: E_(x,y)~P (m^hat_T(x) - y)^2
    - overall test error: avg from training set
        - expectation of cond. test error over training sets
        - Err = E_T Err_T, where Err_T is cond. tst. err. on T
        = E_T E_(x,y)~P (m^hat_T(x) - y)^2
- CV error looks like an estimate of overall test error
    - for leave one out CV: inner summation does not change much, since the m^hat does not change much, so it looks like summation of conditional tst err?
    - and it does estimate the oveall test error, even for LOOCV
- choosing k
    - low k -> high bias
        - training set is smaller, may overestimate the error
    - high k -> high variance
        - training set not well sampled if k is high -> individual training set overlaps too much