### deep generative modeling

simple model for single neurons
- h(x) = w^t x
- non-linear transformaiton y = S(h(x) - theta)
- chain rule
    - delta W_ij = sum_mu (y - o) S'(sum W_ij V_l^mu) V_j^mu
    = sum_mu delta_output V_input
    - where the mu is 'pattern' / training points
    - see slides for backpropagation of gradients
        - delta = s' sum W delta
- uniform approximation: two layer network can appprox. every function
    - k layers can be approx.ed by k-1 layer networks (with exponential elements)
- learning XOR by two layers