### PAC learning

distribution independent deviation bounds
- r(c\*_n) - inf r(c) = r(c\*_n) - r_n(c\*_n) + r_n(c\*_n) - r(c*), where c* is the best c with min. risk
    - r_n(c\*_n) <= r_n(c*), note c*_n min. risk for the training set
    - r(c\*_n) - r_n(c\*_n) <= sup_c |r(c) - r_n(c)|
    - so rhs <= 2 sup_c |r(c) - r_n(c)|
- lemmas: p(x >= eps) <= E x / eps, E exp(sX) <= exp(s^2 (b-a)^2 / 8)
    - then from some tedious math, p(sup_c |r(c) - r_n(c)| > eps) <= 2N exp(-2n eps^2), n is the sample size, N is hypothesis class size
- ERM for hyperplanes
    - n points, choose d points from them and construct 2 hyperplanes from each d points
    - the best classifier will at most make d more mistakes than any other classifier on the training set