### non parametric Bayesian methods

dirichlet distribution
- alpha = (alpha_i), pi = (pi_i) sum pi_i = 1
- Dir(pi | alpha) = prof pi_i^(alpha_i - 1) / B(alpha)
- bayesian network of clustering
    - mu_i ~ N(m, V), Sigma_i ~ IW(v, S)
    - pi ~ Dir(alpha), z_i ~ Cat(pi)
        - non informative prior: assume alpha_i all the same
    - x_i ~ N(mu_z_i, Sigma_z_i)
- d-separation
    - if 3 consecutive nodes of the form...
    - x -> obs -> x
    - x <- obs <- x
    - x <- obs -> x
    - x -> latent and all descents are latent <- x
- prior: mu_k, Sigma_k ~ NIW(...), pi ~ GEM(alpha), which are semi-conjugate priors
    - draw from GEM(alpha): pi_i = Beta(1, alpha) * Prod (1 - pi_j)
    - given pi ~ GEM, z ~ CAt(pi) -> z ~ CRP(alpha)
        - p(z_n joints table k) = # of customers at table_i (alpha if empty) / (alpha + n - 1)
- z_i are exchangeable: z_i ~ z_pi_i (distributionally)
    - (DeFinetti) a sequence of exchangeable Bernoulli X_i, exists a prior p(theta) s.t. all X_i are independent
- {pi, mu, simga} ~ DP(H, alpha)
    - H, base distribution
    - if f ~ DP(H, alpha), f(y) = sum pi_k 1_{theta_k = y}
- collapsed Gibbs sampling, variance reduction
    - z <- p(. | X, z_old)
    - draw a new z per coordinate -> exchangeability